{
    // data
    "name": "dblp",
    "num_time_steps": 8,
    "max_size": 10,
    "seed": 0,
    "multilabel": true,
    "num_workers": 0,
    "sample_walk_len": 15, // # sampling anchor nodes
    "random_walk_len": 15, // # sampling neighbors of anchor nodes
    "structure_patch_type": "triangular_random_walk",
    "max_sim_epochs": 10,
    "n_anchor_patches_structure": 75,
    "subg_n_layers": 2,
    "n_triangular_walks": 10,
    "n_processes": 4,
    "batch_size": 64,
    "meta_paths": "0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0 1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1 1-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1 2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2-2-1-2 0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0 1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1 2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2-1-0-1-2 3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3 1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1 0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0-1-3-1-0",
    // model
    "use_mpn_projection": true,
    "lstm_aggregator": "sum",
    "lstm_n_layers": 2,  
    "subg_n_layers": 2,
    "node_embed_size": 128,
    "subg_hidden_dim": 512,
    "hidden_dim": 128,
    "emb_dim": 128,
    "dropout_prob": 0.8,
    "n_heads": 4,
    "learning_rate": 0.001,
    "num_labels": 5, 
    "loss": "MULTI", //BCE, KL, MULTI
    "alpha": 0.7,
    "beta": 0.3,
    "batch_norm": true,
    // trainer
    "checkpoint_dir": "../model/",
    "top_k": 5,
    "max_epochs": 50,
    "metric": "val_micro_f1",
    "patience": 50,
    "mode": "max"
}